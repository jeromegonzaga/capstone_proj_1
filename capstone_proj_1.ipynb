{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "# Things to do:\n",
    "\n",
    "</div>\n",
    "\n",
    "- 'tips.json'\n",
    "  - rate the 'text' column based on how positive or negative the text is \n",
    "  - get keywords from the 'text' column\n",
    "  - link to 'business.json' file based on 'business_id' column\n",
    "- 'business.json'\n",
    "  - 'categories' column needs to be cleaned up\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# method to change json file into csv file\n",
    "# inputs:\n",
    "#     (1) json_file = name of file, ex. business.json\n",
    "#     (2) output_name = string for output of name\n",
    "#     (3) chunk = amount of lines from the json file to read at a time\n",
    "\n",
    "def json2csv(json_file,partition_size):\n",
    "\n",
    "    json_filepath = '/Users/jeromegonzaga/Documents/Bootcamp/Capstone Project #1_assets/yelp_dataset/' + json_file\n",
    "    jsonObj = pd.read_json(json_filepath, lines = True, chunksize = partition_size, typ = 'frame')\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for chunk in jsonObj:\n",
    "        df = df.append(chunk)\n",
    "\n",
    "    df.to_csv(json_filepath[0:len(json_filepath)-5] + '.csv')\n",
    "    del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.66 s, sys: 944 ms, total: 9.61 s\n",
      "Wall time: 9.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Convert business.json to csv file (File size = 138.3 MB)\n",
    "json2csv('business.json', 900000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.09 s, sys: 1.1 s, total: 10.2 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Convert checkin.json to csv file (File size = 408.8 MB)\n",
    "json2csv('checkin.json', 900000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.33 s, sys: 109 ms, total: 1.44 s\n",
      "Wall time: 1.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Convert photo.json to csv file (File size = 25.7 MB)\n",
    "json2csv('photo.json', 900000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 33s, sys: 54.3 s, total: 5min 27s\n",
      "Wall time: 5min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Convert review.json to csv file (File size = 5.35 GB)\n",
    "json2csv('review.json', 900000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.7 s, sys: 1.22 s, total: 16.9 s\n",
      "Wall time: 15.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Convert tip.json to csv file (File size = 244.5 MB)\n",
    "json2csv('tip.json', 900000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 46s, sys: 45.8 s, total: 2min 32s\n",
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Convert user.json to csv file (File size = 2.49 GB)\n",
    "json2csv('user.json', 900000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business.drop(columns=['latitude', 'longitude',  'postal_code', 'is_open', 'hours'])\\\n",
    "        .sort_values(by=['stars', 'review_count'], ascending=[True, False, False])\\\n",
    "        .groupby('categories').count().head(50).to_csv('categories.csv')\n",
    "#[business['state']=='CA']\n",
    "\n",
    "# tip.drop(columns=['date'])\\\n",
    "#    .head(50).to_csv('tip.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_csv('my_data.csv')\n",
    "# df.head()\n",
    "# df.info()\n",
    "# df.columns\n",
    "# df.describe()\n",
    "# df.column.value_counts()\n",
    "# df.column.plot('hist')\n",
    "# def cleaning_function(row_data):\n",
    "#     # data cleaning steps\n",
    "#     return ...\n",
    "# df.apply(cleaning_function, axis=1)\n",
    "# assert (df.column_data > 0).all()\n",
    "#\n",
    "#\n",
    "# from sys import getsizeof as gs\n",
    "# mb_convert = 0.00000095367432\n",
    "# print(gs(df_business)*mb_convert)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
